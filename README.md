# ğŸ§  Conversational Bot

Private, local, low-latency voice assistant with hotword detection, ASR, **streaming LLM â†’ streaming TTS**, barge-in, and a tidy `/vitals` dashboard.

---

## âœ¨ Whatâ€™s implemented (and how)

* **Wake word with safe fallback** â€” Porcupine hotword; if itâ€™s missing or fails, the app switches to **text-based wake matching** without crashing.
* **ASR with clean endpointing** â€” Faster-Whisper tuned for short turns; **standby** listens in tight windows; **active sessions** auto-detect RO/EN (standby favors EN for reliable hotwords).
* **Streaming LLM â†’ streaming TTS** â€” Real-time token streaming to speech; **time-to-first-token (TTFT)** is measured so replies feel snappy.
* **Audio hygiene** â€” System echo-cancel (AEC), noise suppression, high-pass filter; **AGC off** to avoid noise pumping & false VAD triggers.
* **Stop command flexibility** â€” Use the built-in ASR (â€œstop robotâ€) or an OpenWakeWord model to cut TTS instantly; no Picovoice keys required.
* **No accidental â€œpaâ€¦â€ exits** â€” Session closes **only** on exact goodbyes (e.g., â€œok byeâ€, â€œgataâ€, â€œla revedereâ€).
* **Observability** â€” Prometheus counters + a simple `/vitals` page for round-trip, ASR, TTFT, sessions, turns, errors.
* **Double buffer for seamless TTS** â€” Prevents micro-pauses when the bot speaks; while buffer A plays, buffer B synthesizes the next chunk, then they alternate continuously.
* **English <> Romanian** â€” Improved command & QA flow in English while keeping full Romanian support.
* **Honest fallback** â€” If the bot doesnâ€™t know, it says so (â€œIâ€™m not sure about that yet, but I can look it up if youâ€™d like.â€).
* **Graceful CTRL+C shutdown** â€” One keystroke stops TTS, flushes buffers, dumps a metrics snapshot, and closes all background listeners.

---

## ğŸ”§ Practical setup for users (do this)

1. **Select the echo-cancelled mic**  
   Use the `ec_mic` input (see **Linux audio** + **Audio routing** below).

2. **Tune thresholds for your room**
   - `min_speech_duration`: **1.0â€“1.2s** (utterances shorter than this are ignored)
   - `silence_to_end`: **1200â€“1500 ms** (only for *active* session end)
   - Keep **AGC off** in the OS/driver and inside AEC if exposed.

3. **Keys & env**
   - Put secrets in `.env` (e.g., `PICOVOICE_ACCESS_KEY=...`).
   - Activating a venv **does not** read `.env`. Either:
     - use `python-dotenv` inside the app, **or**
     - `export $(grep -v '^#' .env | xargs)` before `python -m src.app`.

4. **Run with structured logs**
   ```bash
   LOG_LEVEL=INFO LOG_DIR=logs python -m src.app
   ```
   Press **CTRL+C once** to exit cleanly â€” it stops TTS, flushes buffers, dumps a metrics snapshot, and closes all background listeners (no need for `pkill`).

5. **(Optional) Wake Hotword** 
   Picovoice Porcupine for â€œhello robotâ€; if missing, text fallback is used.

6. **Stop command (ASR or hotword)**  
   By default we ship an OpenWakeWord model (`voices/stop_robot.onnx`) that barges TTS the moment you say â€œstop robotâ€. If you prefer ASR-only fallback, change `stop_hotword.engine` to `text` in `configs/core.yaml`.

7. **Route audio correctly (AEC)** âœ see **ğŸ”Š Audio routing (AEC) & pavucontrol** 
   TTS â†’ `Echo-Cancel Sink`, Microphone â†’ `Echo-Cancel Source`. Verify and adjust with pavucontrol.

---

## ğŸ§© Mini flow (pipeline)

**Standby & Wake** â†’ (Porcupine **or** text fallback) 
â†’ **Acknowledgement** (â€œYes, Iâ€™m listening.â€ / â€œDa, te ascult.â€) 
â†’ **Record & endpoint** (VAD on silence; AEC + NS + HPF; AGC off) 
â†’ **ASR** (Faster-Whisper; session auto RO/EN; standby favors EN) 
â†’ **LLM** (streamed generation; **strict-facts** mode to reduce hallucinations) 
â†’ **TTS** (streamed **sentence chunks**) 
â†’ **Double buffer** (A plays, B synthesizes; swap) 
â†’ **Barge-in** (if the user speaks, TTS stops; return to listening) 
â†’ **Session end** (idle timeout **or** exact-match goodbye)

---

## ğŸ™ï¸ Audio Architecture (AEC explained)

**Goal:** prevent the botâ€™s own TTS from being mis-detected as user speech.

**How:** WebRTC AEC uses an **adaptive filter** to estimate the **echo path** (far-end playback â†’ what the mic would hear) and subtracts it from the mic stream. It adapts in real time.

**Extra guards we use:**
* **Exact-match goodbye only** (no partial â€œpaâ€¦â€ exits).
* **Audio similarity veto**: if incoming mic frames highly correlate with recent TTS frames, ignore them.
* **Voice-only gating**: prioritize voiced segments for barge-in (reduces knocks/claps).

---

## ğŸ§ª Biggest build obstacles (and fixes)

* **Echo loop (bot hears itself)** â†’ fixed with **system AEC** + selecting `ec_mic`, AGC off, and a TTS-similarity veto.
* **False exits on â€œpaâ€¦â€** â†’ fixed via **exact-match goodbyes** only.
* **TTS micro-pauses** â†’ fixed with **double buffering**.
* **Noise-triggered barge-in** â†’ improved by **voiced-only gating** and higher minimum speech duration.

> **BIGGEST OBSTACLE â€” reliable barge-in**: now solid with **Cobra VAD**. It also works *without* Picovoice (with WebRTC VAD + thresholds), but Cobra is more robust.

---

## ğŸ§° Linux audio: create echo-cancel devices (PulseAudio / PipeWire)

> Many modern distros run **PipeWire** with a PulseAudio compatibility layer. The commands below work in both setups if the PulseAudio modules are available.

```bash
# 1) Show current default sink/source
pactl info | sed -n -e 's/^Default Sink: /Default Sink: /p' -e 's/^Default Source: /Default Source: /p'

# 2) Unload any old echo-cancel (ignore errors if not loaded)
pactl unload-module module-echo-cancel 2>/dev/null || true

# 3) Load WebRTC echo-cancel on defaults
DEFAULT_SINK="$(pactl info | awk -F': ' '/Default Sink/{print $2}')"
DEFAULT_SOURCE="$(pactl info | awk -F': ' '/Default Source/{print $2}')"

pactl load-module module-echo-cancel \
  aec_method=webrtc \
  aec_args="analog_gain_control=0 digital_gain_control=0" \
  use_master_format=1 \
  sink_master="$DEFAULT_SINK" \
  source_master="$DEFAULT_SOURCE" \
  sink_name=ec_speaker \
  source_name=ec_mic

# 4) Make the echo-cancelled mic default
pactl set-default-source ec_mic

# 5) Verify
pactl list short sources | grep -Ei 'ec_mic|echo|cancel'
pactl list short sinks   | grep -Ei 'ec_speaker|echo|cancel'
```

---

# ğŸ”Š Audio routing (AEC) & pavucontrol

**Target:** route **TTS â†’ `ec_speaker`** and **Mic â†’ `ec_mic`** so AEC has the correct playback reference and barge-in wonâ€™t trigger on your own TTS.

## 1) Install pavucontrol (Ubuntu 22.04/24.04)
```bash
sudo apt update
sudo apt install -y pavucontrol pulseaudio-utils libwebrtc-audio-processing1
```

## 2) Run the app with forced routing
```bash
# (optional) load .env secrets
test -f .env && export $(grep -v '^#' .env | xargs)

# launch using AEC devices
PULSE_SINK=ec_speaker PULSE_SOURCE=ec_mic LOG_LEVEL=INFO LOG_DIR=logs \
  ./.venv/bin/python -m src.app
```

## 3) Verify & adjust in pavucontrol (GUI)
```bash
pavucontrol &
```
- **Playback**: for the *python* process (TTS), choose **`Echo-Cancel Sink`** (ec_speaker).
- **Recording**: for the *python* process (capture), choose **`Echo-Cancel Source`** (ec_mic).
- Recommended volumes: `ec_speaker` **60â€“65%**, `ec_mic` **100â€“120%** (AGC off).

> If `ec_speaker` / `ec_mic` donâ€™t appear in the dropdown, re-run **Create echo-cancel devices** and reopen pavucontrol.
> Once routing looks correct, stop the bot with `CTRL+C` and immediately run `tools/calibrate_audio.py` (see **Calibrate room thresholds**) so the thresholds match this setup.

## 4) Quick CLI checks
```bash
# show defaults
pactl info | sed -n -e 's/^Default Sink: //p' -e 's/^Default Source: //p'

# ec_mic becomes RUNNING while the app is listening
pactl list short sources | grep ec_mic
```

## 5) Troubleshooting
- **â€œNo such entityâ€ when setting volume on ec_*:** the AEC devices arenâ€™t created â€” repeat the **Linux audio** section.
- **Barge-in during TTS:** ensure in pavucontrol that TTS â†’ `ec_speaker`, mic â†’ `ec_mic`. Lower `ec_speaker` to ~60% and (temporarily) set in `configs/audio.yaml`:
  ```yaml
  barge_allow_during_tts: false
  ```
  Optionally raise thresholds:
  ```yaml
  barge_min_voice_ms: 1000-1500
  barge_min_rms_dbfs: -20..-16
  barge_highpass_hz: 240
  ```

---

## ğŸ›ï¸ Calibrate room thresholds (`tools/calibrate_audio.py`)

Use this wizard whenever you change speakers, room layout, or microphone gain so `configs/audio.yaml` reflects your real echo level.

1. **Route once, reuse everywhere.** Launch the bot briefly, open `pavucontrol`, and set the `python` playback stream to `Echo-Cancel Sink` (~60â€“65â€¯% volume) and the recording stream to `Echo-Cancel Source` (100â€¯%). Stop the bot with a single `CTRL+C`.
2. **Run the wizard (â‰ˆ30â€¯s tone).**
   ```bash
   PULSE_SOURCE=ec_mic PULSE_SINK=ec_speaker python tools/calibrate_audio.py --duration 30
   ```
   Stay silent while the tone plays; watch `pavucontrol` if you want to confirm the routing.
3. **Apply the suggestions.** At the end youâ€™ll get lines such as:
   ```
   barge_min_rms_dbfs: 24.3
   barge_highpass_hz: 200
   similarity_veto.max_input_rms_db: 21.8
   similarity_veto.ncc_threshold: 0.78
   ```
   Copy them into `configs/audio.yaml` (keep AGC off). These numbers are derived from the measured speaker leak, so barge-in and the similarity veto trigger only when real speech is present.
4. **Re-run after major changes.** If you move the robot, change speaker volume, or switch microphones, repeat the wizard so the thresholds stay accurate.

---

## ğŸ”„ Models & reasoning

* **ASR**: OpenAI Whisper â†’ **Faster-Whisper** (lower latency on CPU).
* **LLM**: Llama (strong bilingual) + tests with **Qwen-2.5 3B** / **Phi-3 Mini 3.8B**.
* **TTS**: **Piper** (fast, local). Fallback: `pyttsx3`.
* **Containerization**: boosts reliability (consistent deps).
* **â€œTeaser while thinkingâ€**: dropped (complexity > small benefit).

---

## ğŸ—œï¸ Barge-in reliability (with and without Picovoice)

* **Without Picovoice**: WebRTC VAD + tuned thresholds can pause TTS when **human voice** is detected.
* **With Picovoice**: **Cobra VAD** is more robust to noise; **Porcupine** gives instant wake.
* If you donâ€™t have keys, fallback to text matching for wake and to WebRTC VAD for barge-in.
* Text-based stop (`stop_hotword.engine: text`) keeps TTS playing for everything except fuzzy matches on â€œstop robotâ€; the ASR listener runs only during TTS so regular speech wonâ€™t interrupt.

**Pro-tips**
* Raise `min_speech_duration` to avoid coughs/knocks.
* Use voiced-only gating for barge-in.
* Always select **`ec_mic`**.

---

## ğŸ§  LLM prompt (edit to your goals)

Tweak `configs/llm.yaml` (persona, safety rails, bilingual tone, tools, style, facts mode).

---

## ğŸ› ï¸ Commands recap

* **Run app with logs**
```bash
LOG_LEVEL=INFO LOG_DIR=logs python -m src.app
```

* **Load AEC** (see Linux audio)
* **Set default mic to `ec_mic`**
* **Verify**: `pactl list short sources | grep -Ei 'ec_mic|echo|cancel'`

---

## ğŸ”œ To-do (next iterations)

* **Instant feedback while thinking** â€” quick filler if the first token is slow, then keep streaming.
* **Model bake-off** â€” compare **Phi-3 Mini (3.8B)** vs **Qwen-2.5 (3B)** vs current **Llama** (latency / fluency / bilingual accuracy).

---

## ğŸ“¸ Vitals & diagram placeholders

![TTS AEC Schema](src/utils/tts_schema.png)

![Robot Vitals](src/utils/vitals.png)
