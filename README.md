# ğŸ¤– Conversational Bot - Client-Server Architecture

A bilingual (Romanian/English) voice-controlled conversational bot with a **client-server architecture** that allows distributing processing across multiple machines.

---

## ğŸ“‹ Overview

This project implements a voice assistant that can:
- ğŸ¤ Listen for wake words ("hello robot")
- ğŸ§ Transcribe speech to text (ASR)
- ğŸ§  Generate intelligent responses (LLM)
- ğŸ”Š Speak responses naturally (TTS)
- ğŸ›‘ Handle interruptions ("stop robot", "goodbye robot")

### Architecture Modes

|        Mode       |             Description                   |
|-------------------|-------------------------------------------|
| **Local**         | All processing on one machine             |
| **Client-Server** | Audio I/O on client, processing on server |

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       CLIENT            â”‚   HTTP  â”‚        SERVER           â”‚
â”‚                         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                         â”‚
â”‚  ğŸ¤ Audio Capture       â”‚         â”‚  ğŸ§ ASR (Whisper)       â”‚
â”‚  ğŸ‘‚ Wake Word Detection â”‚         â”‚  ğŸ§  LLM (Groq/Ollama)   â”‚
â”‚  ğŸ”Š Audio Playback      â”‚         â”‚  ğŸ—£ï¸ TTS (Edge TTS)      â”‚
â”‚  ğŸ›‘ Stop Keyword        â”‚         â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Ubuntu 22.04/24.04 (or compatible Linux)
- Microphone and speakers
- Internet connection (for Groq LLM and Edge TTS)

### Installation

```bash

python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Set API key for Groq
echo "GROQ_API_KEY=your_key_here" > .env
```

### Running in Local Mode

```bash
# Set configs to local mode (in configs/*.yaml):
# mode: local

source .venv/bin/activate
LOG_LEVEL=INFO python -m src.app
```

### Running in Client-Server Mode

**Terminal 1 - Server:**
```bash
source .venv/bin/activate
python -m src.server.api --host 0.0.0.0 --port 8001
```

**Terminal 2 - Client:**
```bash
# Set configs to remote mode (in configs/*.yaml):
# mode: remote
# remote_host: "localhost"  # or server IP
# remote_port: 8001

source .venv/bin/activate
LOG_LEVEL=INFO python -m src.app
```

---

## ğŸ“ Project Structure

```
Conversational_Bot/
â”œâ”€â”€ configs/                    # Configuration files
â”‚   â”œâ”€â”€ asr.yaml               # ASR settings (Whisper)
â”‚   â”œâ”€â”€ llm.yaml               # LLM settings (Groq/Ollama)
â”‚   â”œâ”€â”€ tts.yaml               # TTS settings (Edge TTS)
â”‚   â”œâ”€â”€ audio.yaml             # Audio & barge-in settings
â”‚   â””â”€â”€ wake.yaml              # Wake word settings
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                 # ğŸ¯ Main client application
â”‚   â”‚
â”‚   â”œâ”€â”€ server/                # ğŸ–¥ï¸ Server API
â”‚   â”‚   â”œâ”€â”€ api.py             # Flask REST endpoints
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ asr/                   # ğŸ§ Speech-to-Text
â”‚   â”‚   â”œâ”€â”€ interface.py       # ASRInterface, LocalASR, RemoteASR
â”‚   â”‚   â”œâ”€â”€ engine_faster.py   # Faster-Whisper implementation
â”‚   â”‚   â””â”€â”€ __init__.py        # Factory: make_asr()
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                   # ğŸ§  Language Model
â”‚   â”‚   â”œâ”€â”€ interface.py       # LLMInterface, LocalLLM, RemoteLLM
â”‚   â”‚   â”œâ”€â”€ engine.py          # Groq/Ollama/OpenAI implementation
â”‚   â”‚   â””â”€â”€ __init__.py        # Factory: make_llm()
â”‚   â”‚
â”‚   â”œâ”€â”€ tts/                   # ğŸ”Š Text-to-Speech
â”‚   â”‚   â”œâ”€â”€ interface.py       # TTSInterface, LocalTTS, RemoteTTS
â”‚   â”‚   â”œâ”€â”€ edge_backend.py    # Microsoft Edge TTS
â”‚   â”‚   â”œâ”€â”€ engine.py          # Piper/pyttsx3 fallback
â”‚   â”‚   â””â”€â”€ __init__.py        # Factory: make_tts()
â”‚   â”‚
â”‚   â”œâ”€â”€ audio/                 # ğŸ¤ Audio processing
â”‚   â”‚   â”œâ”€â”€ input.py           # Audio recording
â”‚   â”‚   â”œâ”€â”€ barge.py           # Barge-in detection
â”‚   â”‚   â”œâ”€â”€ vad.py             # Voice Activity Detection
â”‚   â”‚   â””â”€â”€ stop_keyword_detector.py
â”‚   â”‚
â”‚   â”œâ”€â”€ wake/                  # ğŸ‘‚ Wake word detection
â”‚   â”‚   â””â”€â”€ openwakeword_engine.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                  # âš™ï¸ Core utilities
â”‚   â”‚   â”œâ”€â”€ config.py          # Config loader
â”‚   â”‚   â”œâ”€â”€ logger.py          # Logging setup
â”‚   â”‚   â””â”€â”€ fast_exit.py       # Goodbye detection
â”‚   â”‚
â”‚   â””â”€â”€ telemetry/             # ğŸ“Š Metrics
â”‚       â””â”€â”€ metrics.py         # Prometheus metrics
â”‚
â”œâ”€â”€ voices/                    # ONNX voice models
â”‚   â”œâ”€â”€ hello_robot.onnx       # Wake word model
â”‚   â”œâ”€â”€ goodbye_robot.onnx     # Goodbye detection
â”‚   â””â”€â”€ stop_keyword.onnx      # Stop command model
â”‚
â”œâ”€â”€ models/                    # ASR models (Whisper)
â”œâ”€â”€ tools/                     # Utility scripts
â””â”€â”€ requirements.txt           # Python dependencies
```

---

## âš™ï¸ Configuration

### Client-Server Mode Settings

Each module (ASR, LLM, TTS) can be configured independently in their YAML files:

```yaml
# configs/asr.yaml
mode: remote                # local | remote
remote_host: "192.168.1.100"
remote_port: 8001
remote_timeout: 30.0
```

### Key Configuration Files

|          File        |                 Description            |
|----------------------|----------------------------------------|
| `configs/asr.yaml`   | Whisper model size, language, mode     |
| `configs/llm.yaml`   | Provider (groq/ollama), model, prompts |
| `configs/tts.yaml`   | Voice selection, caching, mode         |
| `configs/audio.yaml` | VAD, barge-in thresholds, stop keyword |
| `configs/wake.yaml`  | Wake phrases, OpenWakeWord settings    |

---

## ğŸ”Œ Server API Endpoints

|       Endpoint      | Method |         Description             |
|---------------------|--------|---------------------------------|
| `/health`           |   GET  | Server health check             |
| `/transcribe`       |   POST | Transcribe audio (WAV â†’ text)   |
| `/transcribe_ro_en` |   POST | Bilingual transcription (RO/EN) |
| `/generate`         |   POST | Generate LLM response           |
| `/generate_stream`  |   POST | Stream LLM tokens               |
| `/synthesize`       |   POST | Synthesize speech (text â†’ MP3)  |

---

## ğŸ”§ Technologies Used

|   Component   |              Technology              |
|---------------|--------------------------------------|
| **ASR**       | Faster-Whisper (Whisper optimized)   |
| **LLM**       | Groq Cloud (llama-3.3-70b) or Ollama |
| **TTS**       | Microsoft Edge TTS (Neural voices)   |
| **Wake Word** | OpenWakeWord (custom ONNX)           |
| **Server**    | Flask (REST API)                     |
| **Audio**     | sounddevice, WebRTC VAD              |

---

## ğŸŒ Deployment on Two Machines

### Step 1: Clone on both machines

```bash
# On both laptops:
git clone https://github.com/Delia63/Conversational_Robot.git
cd Conversational_Robot/Conversational_Bot
git checkout client-server
pip install -r requirements.txt
```

### Step 2: Configure server (Laptop 2)

```bash
# Start server listening on all interfaces
python -m src.server.api --host 0.0.0.0 --port 8001
```

### Step 3: Configure client (Laptop 1)

Edit `configs/asr.yaml`, `configs/llm.yaml`, `configs/tts.yaml`:
```yaml
mode: remote
remote_host: "192.168.1.X"  # Replace with Laptop 2 IP
remote_port: 8001
```

```bash
# Start client
LOG_LEVEL=INFO python -m src.app
```

---

## ğŸ“Š Performance Metrics

|    Metric       |         Typical Value      |
|-----------------|----------------------------|
| ASR Latency     | ~3-5s (Whisper small, CPU) |
| LLM First Token | ~200-300ms (Groq)          |
| Round-trip      | ~2-3s                      |
| TTS Cache Play  | <100ms                     |

Access metrics at: `http://localhost:9108/vitals`

---

## ğŸ¯ Voice Commands

|     Command     |        Action             |
|-----------------|---------------------------|
| "Hello robot"   | Wake up and start listenin|
| "Goodbye robot" | End session               |
| "Stop robot"    | Stop current TTS playback |

---

## ğŸ“ License

This project is for educational and research purposes.

---

## ğŸ”— Related Files

- [INSTALL.md](INSTALL.md) - Detailed installation guide
- [FEATURES.md](FEATURES.md) - Feature documentation
- [LIMITATIONS.md](LIMITATIONS.md) - Known limitations
