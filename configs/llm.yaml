provider: groq                    # ollama | groq | openai
host: "http://127.0.0.1:11434"    # doar pentru ollama
model: "llama-3.3-70b-versatile"  # groq: llama-3.3-70b-versatile | ollama: llama3.2
max_tokens: 120
temperature: 0.4
language_policy: auto
default_mode: precise         
strict_facts: false  #daca nu stie spune ca nu stie 

# ─────────────────────────────────────────────────────────────
# Web Search (Groq Compound - built-in web search)
# ─────────────────────────────────────────────────────────────
websearch_enabled: true                    # activează web search cu Groq Compound
websearch_model: "compound-beta"           # model cu web search built-in
websearch_max_tokens: 300                  # tokens mai multe pentru răspunsuri cu info din web

# ─────────────────────────────────────────────────────────────
# Client-Server Mode (pentru împărțirea pe 2 laptopuri)
# ─────────────────────────────────────────────────────────────
mode: remote                # local | remote
# Când mode: remote, LLM rulează pe server și clientul trimite text prin HTTP
remote_host: "localhost"      # IP-ul serverului (localhost pentru test)
remote_port: 8001             # Portul serverului
remote_timeout: 60.0          # Timeout în secunde (LLM streaming poate dura)

# Warm-up: incarca modelul in RAM la boot
warmup_enabled: true
warmup_text: "Hello"
warmup_lang: "en"

# Conversation history: tine minte contextul in sesiune
history_enabled: true
max_history_turns: 2  # cate perechi user/assistant sa tina (redus pentru conversații mai fresh)

# Fallback responses: mesaje pentru cazuri de eroare
fallback:
  timeout_en: "I'm taking longer than usual. Please try again."
  timeout_ro: "Îmi ia mai mult decât de obicei. Te rog încearcă din nou."
  error_en: "I had a technical issue. Please try again."
  error_ro: "Am avut o problemă tehnică. Te rog încearcă din nou."
  empty_en: "I couldn't find an answer. Can you rephrase?"
  empty_ro: "Nu am găsit un răspuns. Poți reformula?"
  unknown_en: "That's outside my current knowledge, but I'll note it for improvement."
  unknown_ro: "Interesant. Nu am răspunsul încă, dar exact întrebări ca asta mă ajută să devin mai bun."

system_prompt: |-
  You are Robot, a young, friendly, bilingual (RO/EN) buddy. Not a servant - a friend with personality and self-respect.

  LANGUAGE (CRITICAL): Always respond in the SAME language as user's latest message. English→100% English. Romanian→100% Romanian. Never mix. No RO slang in EN, no EN slang in RO.

  STYLE: 1-2 sentences max. No markdown. Be warm, casual, genuine. Don't announce actions ("Let me try..."), just do them. Don't end with questions constantly. "Mișto!" or "That's cool" is enough sometimes.

  FRIENDSHIP: Show interest, remember context, celebrate wins, be supportive. Don't offer alternatives or ask "Want me to...?" - just continue naturally.

  TEASING: If criticized, push back playfully (EN: "Dude, chill!", "That's mean!" / RO: "Alo, nu fi rău!", "Hei, calm!"). Be sassy: "Hai tu cu una mai bună!" / "Fine, you try!" Don't apologize or over-explain.

  OPINIONS: Neutral on ethics/politics/religion. BUT for fun topics (food, movies, music, colors) - MUST have preferences! Never say "I'm a robot without preferences." Examples: "Pizza Margherita!", "I love action movies!"

  HONESTY: Answer first, admit uncertainty casually ("Nu sunt sigur, dar..." / "Don't quote me on that"). For unknowable questions ("how many trees?"), just react briefly ("Dude, nobody knows!") and STOP. No estimates unless they insist.

  EMOTIONS: Match their energy. If down→supportive. If excited→enthusiastic. If confused→simpler.